{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('german_credit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "Age                   0\n",
       "Sex                   0\n",
       "Job                   0\n",
       "Housing               0\n",
       "Saving accounts     183\n",
       "Checking account    394\n",
       "Credit amount         0\n",
       "Duration              0\n",
       "Purpose               0\n",
       "Risk                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little        603\n",
       "moderate      103\n",
       "quite rich     63\n",
       "rich           48\n",
       "Name: Saving accounts, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Saving accounts'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "little      274\n",
       "moderate    269\n",
       "rich         63\n",
       "Name: Checking account, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Checking account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Analysis(refer-- German_Credit_Data_Analysis.ipynb), its clear that Saving accounts and Checking account category \"little\" is in the heigher side of the default ratio, also \"little\" is the MODE value for both the features. In order to impute the missing value of both the features if we use the MODE value, in my opinion data will become a little bias towards \"little\". To eliminate that situation we will replace the missing value with new category \"unknown\". second reason to use new category is that, no of missing value for Checking account is 394 & for Saving accounts it is 183, if we compare these value to there respective features categories we found that both are in the higher side. So, its better to give them a new category instead of using the MODE value for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Saving accounts'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Checking account'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "Age                 0\n",
       "Sex                 0\n",
       "Job                 0\n",
       "Housing             0\n",
       "Saving accounts     0\n",
       "Checking account    0\n",
       "Credit amount       0\n",
       "Duration            0\n",
       "Purpose             0\n",
       "Risk                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    700\n",
       "bad     300\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target Variable\n",
    "data['Risk'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear that Data is imblanced. we will create model with both balanced and imblanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age group'] = pd.qcut(data.Age, q=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical to Numerical Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['Sex','Job','Housing','Saving accounts','Checking account', 'Purpose','Risk','Age group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          int64\n",
       "Age                 int64\n",
       "Sex                 int64\n",
       "Job                 int64\n",
       "Housing             int64\n",
       "Saving accounts     int64\n",
       "Checking account    int64\n",
       "Credit amount       int64\n",
       "Duration            int64\n",
       "Purpose             int64\n",
       "Risk                int64\n",
       "Age group           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in cat_var:\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating separate data set for independent and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Variable\n",
    "X = data.loc[: , ['Sex','Job','Housing','Saving accounts','Checking account','Credit amount','Duration','Purpose','Age group']]\n",
    "# Target Variable\n",
    "Y = data.loc[: , ['Risk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "X = pd.get_dummies(X, columns=['Sex','Housing','Purpose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14694918,  1.83316907, -1.25456565, ...,  1.60356745,\n",
       "        -0.14998296, -0.11020775],\n",
       "       [ 0.14694918, -0.69970702, -0.45902624, ...,  1.60356745,\n",
       "        -0.14998296, -0.11020775],\n",
       "       [-1.38377145, -0.69970702,  1.13205258, ..., -0.62360956,\n",
       "        -0.14998296, -0.11020775],\n",
       "       ..., \n",
       "       [ 0.14694918, -0.69970702,  1.13205258, ...,  1.60356745,\n",
       "        -0.14998296, -0.11020775],\n",
       "       [ 0.14694918, -0.69970702, -1.25456565, ...,  1.60356745,\n",
       "        -0.14998296, -0.11020775],\n",
       "       [ 0.14694918, -0.066488  , -0.45902624, ..., -0.62360956,\n",
       "        -0.14998296, -0.11020775]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train - Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y,test_size = .2,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature ranking with recursive feature elimination and cross-validated selection of the best number of features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=120, min_samples_leaf=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Optimal number of features : 6\n"
     ]
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=rf, step=1, cv=10, scoring='roc_auc', verbose=2)\n",
    "rfecv.fit(X,Y.values.ravel())\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Job', 'Saving accounts', 'Checking account', 'Credit amount',\n",
      "       'Duration', 'Age group'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (X.columns[rfecv.support_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of RFECV, now we know that out of 19(after one hot encoding), only 6 columns are important. Keeping that in mind we will create two models one with having all the features and one with the choosen important features. to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['Job', 'Saving accounts', 'Checking account', 'Credit amount',\n",
    "       'Duration', 'Age group', 'Sex_0', 'Sex_1', 'Housing_0', 'Housing_1',\n",
    "       'Housing_2', 'Purpose_0', 'Purpose_1', 'Purpose_2', 'Purpose_3',\n",
    "       'Purpose_4', 'Purpose_5', 'Purpose_6', 'Purpose_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Job', 0.063090420812146886)\n",
      "('Saving accounts', 0.072940218642288016)\n",
      "('Checking account', 0.14426221755735702)\n",
      "('Credit amount', 0.27203591247634601)\n",
      "('Duration', 0.16392262141705413)\n",
      "('Age group', 0.080647657948974077)\n",
      "('Sex_0', 0.017790552380677144)\n",
      "('Sex_1', 0.01813360638321003)\n",
      "('Housing_0', 0.01268416346599552)\n",
      "('Housing_1', 0.02139199710004561)\n",
      "('Housing_2', 0.015676401468787217)\n",
      "('Purpose_0', 0.018182992295784371)\n",
      "('Purpose_1', 0.027183299757405539)\n",
      "('Purpose_2', 0.0036470970806435398)\n",
      "('Purpose_3', 0.012180996974014001)\n",
      "('Purpose_4', 0.019820967279144654)\n",
      "('Purpose_5', 0.023764590234038315)\n",
      "('Purpose_6', 0.0092292266335041364)\n",
      "('Purpose_7', 0.0034150600925838366)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X, Y.values.ravel())\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(col_name, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important librariesa for model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost \n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import recall_score,precision_score,confusion_matrix,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important variable as per RFECV\n",
    "prediction_var = ['Job', 'Saving accounts', 'Checking account', 'Credit amount','Duration', 'Age group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building with Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1a Logistic Regression with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1a= LogisticRegression()\n",
    "model_1a.fit(x_train, y_train.values.ravel())\n",
    "scores_1a = cross_val_score(model_1a, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1a = model_1a.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1a = accuracy_score(y_val,y_pred_1a)\n",
    "p_s_1a = precision_score(y_val,y_pred_1a)\n",
    "r_s_1a = recall_score(y_val,y_pred_1a)\n",
    "cm_1a = confusion_matrix(y_val,y_pred_1a)\n",
    "f1_1a = f1_score(y_val, y_pred_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1a : 0.73\n",
      "Precision Score for model_1a : 0.728915662651\n",
      "Recall Score for model_1a : 0.930769230769\n",
      "F1 Score for model_1a : 0.817567567568\n",
      "Confusion matrix for model_1a : [[ 25  45]\n",
      " [  9 121]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1a :\", acc_1a)\n",
    "print(\"Precision Score for model_1a :\", p_s_1a)\n",
    "print(\"Recall Score for model_1a :\", r_s_1a)\n",
    "print(\"F1 Score for model_1a :\", f1_1a)\n",
    "print(\"Confusion matrix for model_1a :\", cm_1a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1b Logistic Regression with imp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1b= LogisticRegression()\n",
    "model_1b.fit(x_train[prediction_var], y_train.values.ravel())\n",
    "scores_1b = cross_val_score(model_1b, x_train[prediction_var], y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1b = model_1b.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1b = accuracy_score(y_val,y_pred_1b)\n",
    "p_s_1b = precision_score(y_val,y_pred_1b)\n",
    "r_s_1b = recall_score(y_val,y_pred_1b)\n",
    "cm_1b = confusion_matrix(y_val,y_pred_1b)\n",
    "f1_1b = f1_score(y_val, y_pred_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1b : 0.705\n",
      "Precision Score for model_1b : 0.717791411043\n",
      "Recall Score for model_1b : 0.9\n",
      "F1 Score for model_1b : 0.798634812287\n",
      "Confusion matrix for model_1b : [[ 24  46]\n",
      " [ 13 117]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1b :\", acc_1b)\n",
    "print(\"Precision Score for model_1b :\", p_s_1b)\n",
    "print(\"Recall Score for model_1b :\", r_s_1b)\n",
    "print(\"F1 Score for model_1b :\", f1_1b)\n",
    "print(\"Confusion matrix for model_1b :\", cm_1b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model with only imp features shows some decresase value in every field. Let's go with other algorithms also then we have more clear picture with us."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [5, 10, 15, 20, 30, 50, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200,400,600,800,1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5,10,15,20,30,50]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.0min finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 10, 15, 20, 30, 50, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                               verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2a Random Forest with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best parameter as per result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2a = RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2a.fit(x_train, y_train.values.ravel())\n",
    "scores_2a = cross_val_score(model_2a, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2a = model_2a.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2a = accuracy_score(y_val,y_pred_2a)\n",
    "p_s_2a = precision_score(y_val,y_pred_2a)\n",
    "r_s_2a = recall_score(y_val,y_pred_2a)\n",
    "cm_2a = confusion_matrix(y_val,y_pred_2a)\n",
    "f1_2a = f1_score(y_val, y_pred_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2a : 0.715\n",
      "Precision Score for model_2a : 0.71098265896\n",
      "Recall Score for model_2a : 0.946153846154\n",
      "F1 Score for model_2a : 0.811881188119\n",
      "Confusion matrix for model_2a : [[ 20  50]\n",
      " [  7 123]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2a :\", acc_2a)\n",
    "print(\"Precision Score for model_2a :\", p_s_2a)\n",
    "print(\"Recall Score for model_2a :\", r_s_2a)\n",
    "print(\"F1 Score for model_2a :\", f1_2a)\n",
    "print(\"Confusion matrix for model_2a :\", cm_2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2b Random Forest with important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2b = RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2b.fit(x_train[prediction_var], y_train.values.ravel())\n",
    "scores_2b = cross_val_score(model_2b, x_train[prediction_var], y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2b = model_2b.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2b = accuracy_score(y_val,y_pred_2b)\n",
    "p_s_2b = precision_score(y_val,y_pred_2b)\n",
    "r_s_2b = recall_score(y_val,y_pred_2b)\n",
    "cm_2b = confusion_matrix(y_val,y_pred_2b)\n",
    "f1_2b = f1_score(y_val, y_pred_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2b : 0.745\n",
      "Precision Score for model_2b : 0.742331288344\n",
      "Recall Score for model_2b : 0.930769230769\n",
      "F1 Score for model_2b : 0.825938566553\n",
      "Confusion matrix for model_2b : [[ 28  42]\n",
      " [  9 121]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2b :\", acc_2b)\n",
    "print(\"Precision Score for model_2b :\", p_s_2b)\n",
    "print(\"Recall Score for model_2b :\", r_s_2b)\n",
    "print(\"F1 Score for model_2b :\", f1_2b)\n",
    "print(\"Confusion matrix for model_2b :\", cm_2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a increase in every field for Random forest model with only important features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': [0.3, 0.4, 0.6, 0.8],\n",
      " 'gamma': [0, 1, 5],\n",
      " 'learning_rate': [0.1, 0.01, 0.001, 0.2, 0.02, 0.002],\n",
      " 'max_depth': [3, 4, 5, 7, 8, 10],\n",
      " 'min_child_weight': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000],\n",
      " 'subsample': [0.8, 0.9, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in XGB Classifier\n",
    "n_estimators = [200,400,600,800,1000]\n",
    "# learning rate\n",
    "learning_rate = [0.1,0.01,0.001,0.2,0.02,0.002]\n",
    "# Maximum number of depth in tree\n",
    "max_depth = [3,4,5,7,8,10]\n",
    "# Minimum number of samples required to split a node\n",
    "min_child_weight = [2, 5, 10]\n",
    "# Minimum number of subsamples\n",
    "subsample = [0.8,0.9,1]\n",
    "# Minimum number of colsamples_bytrees\n",
    "colsample_bytree = [0.3,0.4,0.6,0.8]\n",
    "# regularization parameter\n",
    "gamma = [0,1,5]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'learning_rate': learning_rate,\n",
    "               'max_depth': max_depth,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'gamma': gamma}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000], 'learning_rate': [0.1, 0.01, 0.001, 0.2, 0.02, 0.002], 'max_depth': [3, 4, 5, 7, 8, 10], 'min_child_weight': [2, 5, 10], 'subsample': [0.8, 0.9, 1], 'colsample_bytree': [0.3, 0.4, 0.6, 0.8], 'gamma': [0, 1, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "xgb = XGBClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = random_grid, n_iter = 100, cv = 3, \n",
    "                                verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "xgb_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1,\n",
       " 'n_estimators': 200,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.01,\n",
       " 'gamma': 1,\n",
       " 'colsample_bytree': 0.6}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3a XGB Classifier with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3a = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3a.fit(x_train, y_train.values.ravel())\n",
    "scores_3a = cross_val_score(model_3a, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_3a = model_3a.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3a = accuracy_score(y_val,y_pred_3a)\n",
    "p_s_3a = precision_score(y_val,y_pred_3a)\n",
    "r_s_3a = recall_score(y_val,y_pred_3a)\n",
    "cm_3a = confusion_matrix(y_val,y_pred_3a)\n",
    "f1_3a = f1_score(y_val, y_pred_3a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_3a : 0.72\n",
      "Precision Score for model_3a : 0.717647058824\n",
      "Recall Score for model_3a : 0.938461538462\n",
      "F1 Score for model_3a : 0.813333333333\n",
      "Confusion matrix for model_3a : [[ 22  48]\n",
      " [  8 122]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_3a :\", acc_3a)\n",
    "print(\"Precision Score for model_3a :\", p_s_3a)\n",
    "print(\"Recall Score for model_3a :\", r_s_3a)\n",
    "print(\"F1 Score for model_3a :\", f1_3a)\n",
    "print(\"Confusion matrix for model_3a :\", cm_3a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3b XGB Classifier with only important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3b = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3b.fit(x_train[prediction_var], y_train.values.ravel())\n",
    "scores_3b = cross_val_score(model_3b, x_train[prediction_var], y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_3b = model_3b.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3b = accuracy_score(y_val,y_pred_3b)\n",
    "p_s_3b = precision_score(y_val,y_pred_3b)\n",
    "r_s_3b = recall_score(y_val,y_pred_3b)\n",
    "cm_3b = confusion_matrix(y_val,y_pred_3b)\n",
    "f1_3b = f1_score(y_val, y_pred_3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_3b : 0.72\n",
      "Precision Score for model_3b : 0.71511627907\n",
      "Recall Score for model_3b : 0.946153846154\n",
      "F1 Score for model_3b : 0.814569536424\n",
      "Confusion matrix for model_3b: [[ 21  49]\n",
      " [  7 123]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_3b :\", acc_3b)\n",
    "print(\"Precision Score for model_3b :\", p_s_3b)\n",
    "print(\"Recall Score for model_3b :\", r_s_3b)\n",
    "print(\"F1 Score for model_3b :\", f1_3b)\n",
    "print(\"Confusion matrix for model_3b:\", cm_3b)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building with Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to correct the imbalnce dataset\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTEENN(ratio='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smt, y_smt = smt.fit_sample(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smt = pd.DataFrame(data=X_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_smt.rename(columns=dict(zip(X_smt.columns[:],x_train.columns[:])),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Age group</th>\n",
       "      <th>Sex_0</th>\n",
       "      <th>Sex_1</th>\n",
       "      <th>Housing_0</th>\n",
       "      <th>Housing_1</th>\n",
       "      <th>Housing_2</th>\n",
       "      <th>Purpose_0</th>\n",
       "      <th>Purpose_1</th>\n",
       "      <th>Purpose_2</th>\n",
       "      <th>Purpose_3</th>\n",
       "      <th>Purpose_4</th>\n",
       "      <th>Purpose_5</th>\n",
       "      <th>Purpose_6</th>\n",
       "      <th>Purpose_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4308.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job  Saving accounts  Checking account  Credit amount  Duration  Age group  \\\n",
       "0  2.0              0.0               0.0         4308.0      48.0        0.0   \n",
       "1  0.0              0.0               0.0         1193.0      24.0        1.0   \n",
       "\n",
       "   Sex_0  Sex_1  Housing_0  Housing_1  Housing_2  Purpose_0  Purpose_1  \\\n",
       "0    1.0    0.0        0.0        0.0        1.0        1.0        0.0   \n",
       "1    1.0    0.0        0.0        0.0        1.0        0.0        1.0   \n",
       "\n",
       "   Purpose_2  Purpose_3  Purpose_4  Purpose_5  Purpose_6  Purpose_7  \n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_smt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1c Logistic Regression with All the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1c= LogisticRegression()\n",
    "model_1c.fit(X_smt, y_smt.ravel())\n",
    "scores_1c = cross_val_score(model_1c, X_smt, y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1c = model_1c.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1c = accuracy_score(y_val,y_pred_1c)\n",
    "p_s_1c = precision_score(y_val,y_pred_1c)\n",
    "r_s_1c = recall_score(y_val,y_pred_1c)\n",
    "cm_1c = confusion_matrix(y_val,y_pred_1c)\n",
    "f1_1c = f1_score(y_val, y_pred_1c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1c : 0.655\n",
      "Precision Score for model_1c : 0.814432989691\n",
      "Recall Score for model_1c : 0.607692307692\n",
      "F1 Score for model_1c : 0.696035242291\n",
      "Confusion matrix for model_1c : [[52 18]\n",
      " [51 79]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1c :\", acc_1c)\n",
    "print(\"Precision Score for model_1c :\", p_s_1c)\n",
    "print(\"Recall Score for model_1c :\", r_s_1c)\n",
    "print(\"F1 Score for model_1c :\", f1_1c)\n",
    "print(\"Confusion matrix for model_1c :\", cm_1c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1d Logistic Regression with important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d= LogisticRegression()\n",
    "model_1d.fit(X_smt[prediction_var], y_smt.ravel())\n",
    "scores_1d = cross_val_score(model_1d, X_smt[prediction_var], y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1d = model_1d.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1d = accuracy_score(y_val,y_pred_1d)\n",
    "p_s_1d = precision_score(y_val,y_pred_1d)\n",
    "r_s_1d = recall_score(y_val,y_pred_1d)\n",
    "cm_1d = confusion_matrix(y_val,y_pred_1d)\n",
    "f1_1d = f1_score(y_val, y_pred_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1d : 0.665\n",
      "Precision Score for model_1d : 0.824742268041\n",
      "Recall Score for model_1d : 0.615384615385\n",
      "F1 Score for model_1d : 0.704845814978\n",
      "Confusion matrix for model_1d : [[53 17]\n",
      " [50 80]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1d :\", acc_1d)\n",
    "print(\"Precision Score for model_1d :\", p_s_1d)\n",
    "print(\"Recall Score for model_1d :\", r_s_1d)\n",
    "print(\"F1 Score for model_1d :\", f1_1d)\n",
    "print(\"Confusion matrix for model_1d :\", cm_1d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2c Random Forest with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2c= RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2c.fit(X_smt,y_smt.ravel())\n",
    "scores_2c = cross_val_score(model_2c, X_smt, y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2c = model_2c.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2c = accuracy_score(y_val,y_pred_2c)\n",
    "p_s_2c = precision_score(y_val,y_pred_2c)\n",
    "r_s_2c = recall_score(y_val,y_pred_2c)\n",
    "cm_2c = confusion_matrix(y_val,y_pred_2c)\n",
    "f1_2c = f1_score(y_val, y_pred_2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2c : 0.665\n",
      "Precision Score for model_2c : 0.726618705036\n",
      "Recall Score for model_2c : 0.776923076923\n",
      "F1 Score for model_2c : 0.75092936803\n",
      "Confusion matrix for model_2c : [[ 32  38]\n",
      " [ 29 101]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2c :\", acc_2c)\n",
    "print(\"Precision Score for model_2c :\", p_s_2c)\n",
    "print(\"Recall Score for model_2c :\", r_s_2c)\n",
    "print(\"F1 Score for model_2c :\", f1_2c)\n",
    "print(\"Confusion matrix for model_2c :\", cm_2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2d Random Forest with important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2d= RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2d.fit(X_smt[prediction_var],y_smt.ravel())\n",
    "scores_2d = cross_val_score(model_2d, X_smt[prediction_var], y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2d = model_2d.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2d = accuracy_score(y_val,y_pred_2d)\n",
    "p_s_2d = precision_score(y_val,y_pred_2d)\n",
    "r_s_2d = recall_score(y_val,y_pred_2d)\n",
    "cm_2d = confusion_matrix(y_val,y_pred_2d)\n",
    "f1_2d = f1_score(y_val, y_pred_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2d : 0.715\n",
      "Precision Score for model_2d : 0.806722689076\n",
      "Recall Score for model_2d : 0.738461538462\n",
      "F1 Score for model_2d : 0.771084337349\n",
      "Confusion matrix for model_2d : [[47 23]\n",
      " [34 96]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2d :\", acc_2d)\n",
    "print(\"Precision Score for model_2d :\", p_s_2d)\n",
    "print(\"Recall Score for model_2d :\", r_s_2d)\n",
    "print(\"F1 Score for model_2d :\", f1_2d)\n",
    "print(\"Confusion matrix for model_2d :\", cm_2d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3c XGB with all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3c = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3c.fit(X_smt, y_smt)\n",
    "scores_3c = cross_val_score(model_3c, X_smt, y_smt, cv=5, scoring='f1')\n",
    "y_pred_3c = model_3c.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3c = accuracy_score(y_val,y_pred_3c)\n",
    "p_s_3c = precision_score(y_val,y_pred_3c)\n",
    "r_s_3c = recall_score(y_val,y_pred_3c)\n",
    "cm_3c = confusion_matrix(y_val,y_pred_3c)\n",
    "f1_3c = f1_score(y_val, y_pred_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_3c : 0.705\n",
      "Precision Score for model_3c : 0.751773049645\n",
      "Recall Score for model_3c : 0.815384615385\n",
      "F1 Score for model_3c : 0.782287822878\n",
      "Confusion matrix for model_3c : [[ 35  35]\n",
      " [ 24 106]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_3c :\", acc_3c)\n",
    "print(\"Precision Score for model_3c :\", p_s_3c)\n",
    "print(\"Recall Score for model_3c :\", r_s_3c)\n",
    "print(\"F1 Score for model_3c :\", f1_3c)\n",
    "print(\"Confusion matrix for model_3c :\", cm_3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3d XGB with important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3d = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3d.fit(X_smt[prediction_var], y_smt)\n",
    "scores_3d = cross_val_score(model_3d, X_smt[prediction_var], y_smt, cv=5, scoring='f1')\n",
    "y_pred_3d = model_3d.predict(x_val[prediction_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3d = accuracy_score(y_val,y_pred_3d)\n",
    "p_s_3d = precision_score(y_val,y_pred_3d)\n",
    "r_s_3d = recall_score(y_val,y_pred_3d)\n",
    "cm_3d = confusion_matrix(y_val,y_pred_3d)\n",
    "f1_3d = f1_score(y_val, y_pred_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_3d : 0.735\n",
      "Precision Score for model_3d : 0.798449612403\n",
      "Recall Score for model_3d : 0.792307692308\n",
      "F1 Score for model_3d : 0.795366795367\n",
      "Confusion matrix for model_3d : [[ 44  26]\n",
      " [ 27 103]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_3d :\", acc_3d)\n",
    "print(\"Precision Score for model_3d :\", p_s_3d)\n",
    "print(\"Recall Score for model_3d :\", r_s_3d)\n",
    "print(\"F1 Score for model_3d :\", f1_3d)\n",
    "print(\"Confusion matrix for model_3d :\", cm_3d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building using PCA and Imblanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 4)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_val = pca.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1e Logistic Regression+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1e= LogisticRegression()\n",
    "model_1e.fit(x_train, y_train.values.ravel())\n",
    "scores_1e = cross_val_score(model_1e, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1e = model_1e.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1e = accuracy_score(y_val,y_pred_1e)\n",
    "p_s_1e = precision_score(y_val,y_pred_1e)\n",
    "r_s_1e = recall_score(y_val,y_pred_1e)\n",
    "cm_1e = confusion_matrix(y_val,y_pred_1e)\n",
    "f1_1e = f1_score(y_val, y_pred_1e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1e : 0.705\n",
      "Precision Score for model_1e : 0.717791411043\n",
      "Recall Score for model_1e : 0.9\n",
      "F1 Score for model_1e : 0.798634812287\n",
      "Confusion matrix for model_1e : [[ 24  46]\n",
      " [ 13 117]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1e :\", acc_1e)\n",
    "print(\"Precision Score for model_1e :\", p_s_1e)\n",
    "print(\"Recall Score for model_1e :\", r_s_1e)\n",
    "print(\"F1 Score for model_1e :\", f1_1e)\n",
    "print(\"Confusion matrix for model_1e :\", cm_1e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2e Random Forest+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2e= RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2e.fit(x_train,y_train.values.ravel())\n",
    "scores_2e = cross_val_score(model_2e, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2e = model_2e.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2e = accuracy_score(y_val,y_pred_2e)\n",
    "p_s_2e = precision_score(y_val,y_pred_2e)\n",
    "r_s_2e = recall_score(y_val,y_pred_2e)\n",
    "cm_2e = confusion_matrix(y_val,y_pred_2e)\n",
    "f1_2e = f1_score(y_val, y_pred_2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2e : 0.74\n",
      "Precision Score for model_2e : 0.740740740741\n",
      "Recall Score for model_2e : 0.923076923077\n",
      "F1 Score for model_2e : 0.821917808219\n",
      "Confusion matrix for model_2e : [[ 28  42]\n",
      " [ 10 120]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2e :\", acc_2e)\n",
    "print(\"Precision Score for model_2e :\", p_s_2e)\n",
    "print(\"Recall Score for model_2e :\", r_s_2e)\n",
    "print(\"F1 Score for model_2e :\", f1_2e)\n",
    "print(\"Confusion matrix for model_2e :\", cm_2e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model 3e XGB+PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3e = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3e.fit(x_train, y_train.values.ravel())\n",
    "scores_3e = cross_val_score(model_3e, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_3e = model_3e.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3e = accuracy_score(y_val,y_pred_3e)\n",
    "p_s_3e = precision_score(y_val,y_pred_3e)\n",
    "r_s_3e = recall_score(y_val,y_pred_3e)\n",
    "cm_3e = confusion_matrix(y_val,y_pred_3e)\n",
    "f1_3e = f1_score(y_val, y_pred_3e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_3e : 0.755\n",
      "Precision Score for model_3e : 0.748466257669\n",
      "Recall Score for model_3e : 0.938461538462\n",
      "F1 Score for model_3e : 0.832764505119\n",
      "Confusion matrix for model_3e : [[ 29  41]\n",
      " [  8 122]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_3e :\", acc_3e)\n",
    "print(\"Precision Score for model_3e :\", p_s_3e)\n",
    "print(\"Recall Score for model_3e :\", r_s_3e)\n",
    "print(\"F1 Score for model_3e :\", f1_3e)\n",
    "print(\"Confusion matrix for model_3e :\", cm_3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with PCA and Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 4)\n",
    "X_smt = pca.fit_transform(X_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1f Logistic Regression+PCA+SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1f= LogisticRegression()\n",
    "model_1f.fit(X_smt, y_smt.ravel())\n",
    "scores_1f = cross_val_score(model_1f, X_smt, y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_1f = model_1f.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1f = accuracy_score(y_val,y_pred_1f)\n",
    "p_s_1f = precision_score(y_val,y_pred_1f)\n",
    "r_s_1f = recall_score(y_val,y_pred_1f)\n",
    "cm_1f = confusion_matrix(y_val,y_pred_1f)\n",
    "f1_1f = f1_score(y_val, y_pred_1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_1f : 0.585\n",
      "Precision Score for model_1f : 0.78313253012\n",
      "Recall Score for model_1f : 0.5\n",
      "F1 Score for model_1f : 0.610328638498\n",
      "Confusion matrix for model_1f : [[52 18]\n",
      " [65 65]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_1f :\", acc_1f)\n",
    "print(\"Precision Score for model_1f :\", p_s_1f)\n",
    "print(\"Recall Score for model_1f :\", r_s_1f)\n",
    "print(\"F1 Score for model_1f :\", f1_1f)\n",
    "print(\"Confusion matrix for model_1f :\", cm_1f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2f Random Forest+PCA+SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2f= RandomForestClassifier(n_estimators=600,bootstrap= True,min_samples_leaf=4,min_samples_split= 2,\n",
    "                               max_features= 'sqrt',max_depth= None,random_state=42, n_jobs = -1)\n",
    "model_2f.fit(X_smt,y_smt.ravel())\n",
    "scores_2f = cross_val_score(model_2f, X_smt, y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_2f = model_2f.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2f = accuracy_score(y_val,y_pred_2f)\n",
    "p_s_2f = precision_score(y_val,y_pred_2f)\n",
    "r_s_2f = recall_score(y_val,y_pred_2f)\n",
    "cm_2f = confusion_matrix(y_val,y_pred_2f)\n",
    "f1_2f = f1_score(y_val, y_pred_2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for model_2f : 0.505\n",
      "Precision Score for model_2f : 0.682352941176\n",
      "Recall Score for model_2f : 0.446153846154\n",
      "F1 Score for model_2f : 0.539534883721\n",
      "Confusion matrix for model_2f : [[43 27]\n",
      " [72 58]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score for model_2f :\", acc_2f)\n",
    "print(\"Precision Score for model_2f :\", p_s_2f)\n",
    "print(\"Recall Score for model_2f :\", r_s_2f)\n",
    "print(\"F1 Score for model_2f :\", f1_2f)\n",
    "print(\"Confusion matrix for model_2f :\", cm_2f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3f XGB Classifier+PCA+SMOTEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3f = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3f.fit(X_smt, y_smt.ravel())\n",
    "scores_3f = cross_val_score(model_3f, X_smt, y_smt.ravel(), cv=5, scoring='f1')\n",
    "y_pred_3f = model_3f.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_3f = accuracy_score(y_val,y_pred_3f)\n",
    "p_s_3f = precision_score(y_val,y_pred_3f)\n",
    "r_s_3f = recall_score(y_val,y_pred_3f)\n",
    "cm_3f = confusion_matrix(y_val,y_pred_3f)\n",
    "f1_3f = f1_score(y_val, y_pred_3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.51\n",
      "Precision Score : 0.7\n",
      "Recall Score : 0.430769230769\n",
      "F1 Score : 0.533333333333\n",
      "Confusion matrix : [[46 24]\n",
      " [74 56]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score :\", acc_3f)\n",
    "print(\"Precision Score :\", p_s_3f)\n",
    "print(\"Recall Score :\", r_s_3f)\n",
    "print(\"F1 Score :\", f1_3f)\n",
    "print(\"Confusion matrix :\", cm_3f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 18 different model using 3 algorithms \"Logistic Regression\", \"Random Forest Classifier\" & \"XGB Classifier\", with the help of \"PCA\" and \"SMOTEEN\", finally we have the result of all the model.     \n",
    "By doing the comparision its quite clear that MODEL 3e i.e (XGB Classifier with PCA) has the best figure compare to every other model. So our final and best to go model is MODEL 3e. \n",
    "\n",
    "Below is the output result of MODEL 3e\n",
    "\n",
    "Accuracy Score for model_3e : 0.755        \n",
    "Precision Score for model_3e : 0.748466257669     \n",
    "Recall Score for model_3e : 0.938461538462      \n",
    "F1 Score for model_3e : 0.832764505119      "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL STRUCTURE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_3e = XGBClassifier( learning_rate =0.01, n_estimators=200, max_depth=10,min_child_weight=2, gamma=1, \n",
    "                    subsample=1, colsample_bytree=0.6,seed=27)\n",
    "model_3e.fit(x_train, y_train.values.ravel())\n",
    "scores_3e = cross_val_score(model_3e, x_train, y_train.values.ravel(), cv=5, scoring='f1')\n",
    "y_pred_3e = model_3e.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
